//! Integration tests for provider thinking block compatibility.
//!
//! These tests verify real API behavior when handling thinking blocks
//! across different providers. They require actual API keys to run.
//!
//! Run with: cargo test --test provider_thinking_compat -- --ignored
//!
//! Required environment variables:
//! - GLM_API_KEY: Z.AI API key for GLM-4.7

use serde_json::{json, Value};
use std::env;

/// Test helper to make requests to GLM Anthropic-compatible endpoint
async fn glm_anthropic_request(body: Value) -> Result<(u16, Value), String> {
    let api_key = env::var("GLM_API_KEY")
        .map_err(|_| "GLM_API_KEY not set")?;

    let client = reqwest::Client::new();
    let response = client
        .post("https://api.z.ai/api/anthropic/v1/messages")
        .header("x-api-key", &api_key)
        .header("anthropic-version", "2023-06-01")
        .header("content-type", "application/json")
        .json(&body)
        .send()
        .await
        .map_err(|e| format!("Request failed: {}", e))?;

    let status = response.status().as_u16();
    let body: Value = response
        .json()
        .await
        .map_err(|e| format!("Failed to parse response: {}", e))?;

    Ok((status, body))
}

/// Test: Send thinking block with fake signature to GLM
///
/// This tests what happens when we send a thinking block with a signature
/// that was NOT generated by GLM (simulating switch from Anthropic to GLM).
#[tokio::test]
#[ignore = "requires GLM_API_KEY"]
async fn test_glm_with_foreign_thinking_signature() {
    let body = json!({
        "model": "glm-4.7",
        "max_tokens": 1024,
        "messages": [
            {
                "role": "user",
                "content": "What is 2+2?"
            },
            {
                "role": "assistant",
                "content": [
                    {
                        "type": "thinking",
                        "thinking": "Let me calculate this simple addition.",
                        "signature": "FAKE_SIGNATURE_FROM_ANTHROPIC_abc123xyz"
                    },
                    {
                        "type": "text",
                        "text": "2+2 equals 4."
                    }
                ]
            },
            {
                "role": "user",
                "content": "Are you sure?"
            }
        ]
    });

    let result = glm_anthropic_request(body).await;

    match result {
        Ok((status, response)) => {
            println!("Status: {}", status);
            println!("Response: {}", serde_json::to_string_pretty(&response).unwrap());

            if status == 400 {
                println!("\n==> GLM REJECTS foreign signatures (400 error)");
                println!("    This means we MUST transform thinking blocks when switching providers");
            } else if status == 200 {
                println!("\n==> GLM ACCEPTS foreign signatures (200 OK)");
                println!("    This means GLM ignores/strips the signature field");
            } else {
                println!("\n==> Unexpected status code: {}", status);
            }
        }
        Err(e) => {
            println!("Error: {}", e);
        }
    }
}

/// Test: Send thinking block WITHOUT signature to GLM
///
/// This tests what happens when we strip the signature before sending.
#[tokio::test]
#[ignore = "requires GLM_API_KEY"]
async fn test_glm_with_thinking_no_signature() {
    let body = json!({
        "model": "glm-4.7",
        "max_tokens": 1024,
        "messages": [
            {
                "role": "user",
                "content": "What is 2+2?"
            },
            {
                "role": "assistant",
                "content": [
                    {
                        "type": "thinking",
                        "thinking": "Let me calculate this simple addition."
                        // No signature field
                    },
                    {
                        "type": "text",
                        "text": "2+2 equals 4."
                    }
                ]
            },
            {
                "role": "user",
                "content": "Are you sure?"
            }
        ]
    });

    let result = glm_anthropic_request(body).await;

    match result {
        Ok((status, response)) => {
            println!("Status: {}", status);
            println!("Response: {}", serde_json::to_string_pretty(&response).unwrap());

            if status == 400 {
                println!("\n==> GLM REJECTS thinking without signature (400 error)");
                println!("    This means we MUST convert thinking to text format");
            } else if status == 200 {
                println!("\n==> GLM ACCEPTS thinking without signature (200 OK)");
                println!("    This means DropSignature mode will work");
            } else {
                println!("\n==> Unexpected status code: {}", status);
            }
        }
        Err(e) => {
            println!("Error: {}", e);
        }
    }
}

/// Test: Send thinking converted to text block
///
/// This tests the ConvertToText approach - replacing thinking with plain text.
#[tokio::test]
#[ignore = "requires GLM_API_KEY"]
async fn test_glm_with_thinking_as_text() {
    let body = json!({
        "model": "glm-4.7",
        "max_tokens": 1024,
        "messages": [
            {
                "role": "user",
                "content": "What is 2+2?"
            },
            {
                "role": "assistant",
                "content": [
                    {
                        "type": "text",
                        "text": "Let me calculate this simple addition."
                    },
                    {
                        "type": "text",
                        "text": "2+2 equals 4."
                    }
                ]
            },
            {
                "role": "user",
                "content": "Are you sure?"
            }
        ]
    });

    let result = glm_anthropic_request(body).await;

    match result {
        Ok((status, response)) => {
            println!("Status: {}", status);
            println!("Response: {}", serde_json::to_string_pretty(&response).unwrap());

            if status == 200 {
                println!("\n==> GLM ACCEPTS thinking as plain text (200 OK)");
                println!("    ConvertToText mode is a safe fallback");
            } else {
                println!("\n==> Unexpected status: {}", status);
            }
        }
        Err(e) => {
            println!("Error: {}", e);
        }
    }
}

/// Test: Send thinking with <think> tags
///
/// This tests the ConvertToTags approach.
#[tokio::test]
#[ignore = "requires GLM_API_KEY"]
async fn test_glm_with_think_tags() {
    let body = json!({
        "model": "glm-4.7",
        "max_tokens": 1024,
        "messages": [
            {
                "role": "user",
                "content": "What is 2+2?"
            },
            {
                "role": "assistant",
                "content": [
                    {
                        "type": "text",
                        "text": "<think>Let me calculate this simple addition.</think>"
                    },
                    {
                        "type": "text",
                        "text": "2+2 equals 4."
                    }
                ]
            },
            {
                "role": "user",
                "content": "Are you sure?"
            }
        ]
    });

    let result = glm_anthropic_request(body).await;

    match result {
        Ok((status, response)) => {
            println!("Status: {}", status);
            println!("Response: {}", serde_json::to_string_pretty(&response).unwrap());

            if status == 200 {
                println!("\n==> GLM ACCEPTS <think> tags (200 OK)");

                // Check if response contains thinking in any form
                let content = response.get("content");
                println!("    Response content structure: {:?}", content);
            } else {
                println!("\n==> Unexpected status: {}", status);
            }
        }
        Err(e) => {
            println!("Error: {}", e);
        }
    }
}

/// Test: Check GLM response format for thinking
///
/// This tests what format GLM returns when it generates thinking.
#[tokio::test]
#[ignore = "requires GLM_API_KEY"]
async fn test_glm_thinking_response_format() {
    let body = json!({
        "model": "glm-4.7",
        "max_tokens": 2048,
        "thinking": {
            "type": "enabled",
            "budget_tokens": 1000
        },
        "messages": [
            {
                "role": "user",
                "content": "Think step by step: what is 17 * 23?"
            }
        ]
    });

    let result = glm_anthropic_request(body).await;

    match result {
        Ok((status, response)) => {
            println!("Status: {}", status);
            println!("Response: {}", serde_json::to_string_pretty(&response).unwrap());

            if status == 200 {
                if let Some(content) = response.get("content").and_then(|c| c.as_array()) {
                    for (i, block) in content.iter().enumerate() {
                        let block_type = block.get("type").and_then(|t| t.as_str());
                        let has_signature = block.get("signature").is_some();
                        let has_thinking = block.get("thinking").is_some();

                        println!("\n==> Block {}: type={:?}, has_signature={}, has_thinking={}",
                                 i, block_type, has_signature, has_thinking);

                        if block_type == Some("thinking") && has_signature {
                            println!("    GLM returns Anthropic-style thinking blocks WITH signature");
                        } else if block_type == Some("thinking") && !has_signature {
                            println!("    GLM returns thinking blocks WITHOUT signature");
                        }
                    }
                }
            }
        }
        Err(e) => {
            println!("Error: {}", e);
        }
    }
}

/// Test: Full cycle - get response from GLM, then send to GLM with that history
///
/// This simulates: GLM response -> switch backend -> new request with history
#[tokio::test]
#[ignore = "requires GLM_API_KEY"]
async fn test_full_cycle_glm_to_glm() {
    // Step 1: Get a response from GLM with thinking enabled
    let first_request = json!({
        "model": "glm-4.7",
        "max_tokens": 2048,
        "thinking": {
            "type": "enabled",
            "budget_tokens": 1000
        },
        "messages": [
            {
                "role": "user",
                "content": "What is 5+3? Think step by step."
            }
        ]
    });

    let (status1, response1) = match glm_anthropic_request(first_request).await {
        Ok(r) => r,
        Err(e) => {
            println!("First request failed: {}", e);
            return;
        }
    };

    println!("=== Step 1: Initial GLM response ===");
    println!("Status: {}", status1);
    println!("Response: {}", serde_json::to_string_pretty(&response1).unwrap());

    if status1 != 200 {
        println!("First request failed, cannot continue");
        return;
    }

    // Step 2: Build second request with history from first response
    let content_blocks = response1.get("content").and_then(|c| c.as_array());
    if content_blocks.is_none() {
        println!("No content in response");
        return;
    }

    let second_request = json!({
        "model": "glm-4.7",
        "max_tokens": 1024,
        "messages": [
            {
                "role": "user",
                "content": "What is 5+3? Think step by step."
            },
            {
                "role": "assistant",
                "content": content_blocks.unwrap()
            },
            {
                "role": "user",
                "content": "Now what is 10+20?"
            }
        ]
    });

    println!("\n=== Step 2: Second request with history ===");
    println!("Request: {}", serde_json::to_string_pretty(&second_request).unwrap());

    let (status2, response2) = match glm_anthropic_request(second_request).await {
        Ok(r) => r,
        Err(e) => {
            println!("Second request failed: {}", e);
            return;
        }
    };

    println!("\nStatus: {}", status2);
    println!("Response: {}", serde_json::to_string_pretty(&response2).unwrap());

    if status2 == 200 {
        println!("\n==> Full cycle GLM -> GLM WORKS");
    } else {
        println!("\n==> Full cycle GLM -> GLM FAILS with {}", status2);
        if let Some(error) = response2.get("error") {
            println!("Error details: {}", error);
        }
    }
}

/// Test: Full cycle simulating Anthropic -> GLM switch
///
/// We simulate Anthropic response format and send to GLM
#[tokio::test]
#[ignore = "requires GLM_API_KEY"]
async fn test_full_cycle_simulated_anthropic_to_glm() {
    // Simulate what an Anthropic response looks like
    // (with a realistic-looking but fake signature)
    let simulated_anthropic_history = json!({
        "model": "glm-4.7",
        "max_tokens": 1024,
        "messages": [
            {
                "role": "user",
                "content": "What is 5+3?"
            },
            {
                "role": "assistant",
                "content": [
                    {
                        "type": "thinking",
                        "thinking": "I need to add 5 and 3. 5 + 3 = 8.",
                        "signature": "WaUjzkypQ2mUEVM36O2TxuC06KN8xyfbJwyem2dw3URve/op91XWHOEBLLqIOMfFG/UvLEczmEsUjavLsomeMoreBase64DataHere=="
                    },
                    {
                        "type": "text",
                        "text": "5 + 3 = 8"
                    }
                ]
            },
            {
                "role": "user",
                "content": "Now what is 10+20?"
            }
        ]
    });

    println!("=== Test: Simulated Anthropic history -> GLM ===");
    println!("Request: {}", serde_json::to_string_pretty(&simulated_anthropic_history).unwrap());

    let (status, response) = match glm_anthropic_request(simulated_anthropic_history).await {
        Ok(r) => r,
        Err(e) => {
            println!("Request failed: {}", e);
            return;
        }
    };

    println!("\nStatus: {}", status);
    println!("Response: {}", serde_json::to_string_pretty(&response).unwrap());

    if status == 200 {
        println!("\n==> Anthropic-style history accepted by GLM");
    } else {
        println!("\n==> GLM REJECTS Anthropic-style history with {}", status);
        if let Some(error) = response.get("error") {
            println!("Error details: {}", error);
        }
    }
}

/// Test: Anthropic with GLM-generated signature (reverse direction)
///
/// This would test what happens when we send GLM's signature to Anthropic.
/// Requires ANTHROPIC_API_KEY.
#[tokio::test]
#[ignore = "requires ANTHROPIC_API_KEY"]
async fn test_anthropic_with_foreign_signature() {
    let api_key = match env::var("ANTHROPIC_API_KEY") {
        Ok(k) => k,
        Err(_) => {
            println!("ANTHROPIC_API_KEY not set, skipping");
            return;
        }
    };

    let body = json!({
        "model": "claude-sonnet-4-20250514",
        "max_tokens": 1024,
        "messages": [
            {
                "role": "user",
                "content": "What is 2+2?"
            },
            {
                "role": "assistant",
                "content": [
                    {
                        "type": "thinking",
                        "thinking": "Let me calculate this.",
                        "signature": "FAKE_SIGNATURE_FROM_GLM_xyz789"
                    },
                    {
                        "type": "text",
                        "text": "4"
                    }
                ]
            },
            {
                "role": "user",
                "content": "Thanks!"
            }
        ]
    });

    let client = reqwest::Client::new();
    let response = client
        .post("https://api.anthropic.com/v1/messages")
        .header("x-api-key", &api_key)
        .header("anthropic-version", "2023-06-01")
        .header("content-type", "application/json")
        .json(&body)
        .send()
        .await;

    match response {
        Ok(resp) => {
            let status = resp.status().as_u16();
            let body: Value = resp.json().await.unwrap_or(json!({}));

            println!("Status: {}", status);
            println!("Response: {}", serde_json::to_string_pretty(&body).unwrap());

            if status == 400 {
                println!("\n==> Anthropic REJECTS foreign signatures (400 error)");
            } else if status == 200 {
                println!("\n==> Anthropic ACCEPTS foreign signatures (200 OK) - unexpected!");
            }
        }
        Err(e) => {
            println!("Error: {}", e);
        }
    }
}
